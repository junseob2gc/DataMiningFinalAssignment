*********************************************************
***************BDAT 1002 : Big Data Systems**************
		    Saber Amini
		Hive - Loading Hive Tables
*********************************************************
*********************************************************

### CREATE A TABLE FOR STOCKS ###
/*First switch to the database*/

hive> USE stocks_db;

hive> CREATE TABLE IF NOT EXISTS stocks (
exch STRING,
symbol STRING,
ymd STRING,
price_open FLOAT,
price_high FLOAT,
price_low FLOAT,
price_close FLOAT,
volume INT,
price_adj_close FLOAT)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
TBLPROPERTIES ('creator'='BDAT 1002 class', 'created_on' = '2018-06-21', 'description'='This table holds daily stocks data.');

/*To make sure table is there, use following command */

hive> SHOW tables;


### DESCRIBE TABLE TO GET DETAILS ABOUT TABLE ###

hive> DESCRIBE FORMATTED stocks;

-- The important attribute is "location" - this is the location in HDFS where the data for this table will be stored.

### COPY THE STOCKS DATASET TO HDFS IF YOU HAVEN'T DONE SO###

hadoop fs -copyFromLocal /home/cloudera/Downloads/stocks /BDAT1002/hive/stocks

-- check to see if the file is in the directory

hadoop fs -ls /BDAT1002/hive/

*** You can also check HDFS files in Hive shell, just use a exclamation mark (!) to start the command

hive> !hadoop fs -ls /BDAT1002/hive/stocks;

### *** METHOD 1 *** LOAD DATASAET USING LOAD COMMAND ###

-- this command MOVES the data from the hive folder into the location folder specified in the Metadata

hive> LOAD DATA INPATH '/BDAT1002/hive/stocks' INTO TABLE stocks;

-- Since the file has been be moved, the following directory will be empty

hive> !hadoop fs -ls /BDAT1002/hive/;

--check out the location of the data for this table

hive> DESCRIBE FORMATTED stocks;

-- display the contents of the folder (should see the stocks data)

hive> !hadoop fs -ls /user/hive/warehouse/stocks_db.db/stocks;

-- very powerful, we now have our data in table format and can use familiar SQL queries

hive> SELECT * FROM stocks LIMIT 100;

### *** METHOD 2 *** LOAD DATASET USING CTAS ###

-- This runs a MapReduce job

hive> CREATE TABLE stocks_ctas AS SELECT * FROM stocks;

-- Let's see the location of the data for this table

hive> DESCRIBE FORMATTED stocks_ctas;

-- Look at the location

hive> !hadoop fs -ls /user/hive/warehouse/stocks_db.db/stocks_ctas;

### *** METHOD 3a *** LOAD DATASET USING INSERT..SELECT STATEMENT###

-- Assume you already have the table and want to update/overwrite the data
-- Here is the way to APPEND data to a table (that already exists).

hive> INSERT INTO TABLE stocks_ctas
h     SELECT s.* FROM stocks s;


hive> INSERT INTO TABLE stocks_ctas
SELECT * FROM stocks;


hive> !hadoop fs -ls /user/hive/warehouse/stocks_db.db/stocks_ctas;

hive> SELECT * FROM stocks_ctas;

### *** METHOD 3b *** LOAD DATASET USING INSERT OVERWRITE ###

-- This command will overwrite the data in an already created table

hive> INSERT OVERWRITE TABLE stocks_ctas
    > SELECT s.* FROM stocks s;

-- You can check and see that the file has been overwritten
hive> !hadoop fs -ls /user/hive/warehouse/stocks_db.db/stocks_ctas;


### LOCATION ATTRIBUTE & LOADING DATA ### 

** Make sure stocks dataset is saved in this hive folder **

hadoop fs -copyFromLocal /home/cloudera/Downloads/stocks /BDAT1002/hive/stocks

-- OR do it from HDFS 

hadoop fs -cp /BDAT1002/stocks /BDAT1002/hive/.

-- make sure the copy was successful
 
hadoop fs -ls /BDAT1002/hive/

-- Here we are creating a table and asking hive to use the mentioned location not the default location under warehouse

hive> CREATE TABLE IF NOT EXISTS stocks_loc (
exch STRING,
symbol STRING,
ymd STRING,
price_open FLOAT,
price_high FLOAT,
price_low FLOAT,
price_close FLOAT,
volume INT,
price_adj_close FLOAT)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/BDAT1002/hive/'
TBLPROPERTIES ('creator'='BDAT 1002 class', 'created_on' = '2018-06-21', 'description'='This table holds stocks dataset.');

-- you can manually load the data set into this location or use a tool (like a Pig script) to do this overnight

-- If you run a describe formatted command, you'll see that the location is no longer the default warehouse location

hive> DESCRIBE FORMATTED stocks_loc;

-- Now select some rows, you'll see that it will load data

hive> SELECT * FROM stocks_loc LIMIT 100;